{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Agent Memory Hub: Region-Governed Memory for AI Agents","text":"<p>Agent Memory Hub is the enterprise-standard solution for managing long-term memory for AI agents with strict region governance. Designed for developers building scalable agentic workflows, it provides a unified interface to store, recall, and manage agent state across diverse storage backends while ensuring compliance with data residency laws (GDPR, CCPA).</p> <p>Whether you are building a simple chatbot or a complex multi-agent system, <code>agent-memory-hub</code> abstracts the complexity of state management, letting you focus on agent logic.</p>"},{"location":"#what-is-agent-memory-hub","title":"\ud83d\ude80 What is Agent Memory Hub?","text":"<p>Agent Memory Hub is a Python SDK that acts as a middleware between your AI agents (built with LangChain, AutoGen, OpenAI, etc.) and your storage infrastructure. It creates a structured \"brain\" for your agents where every interaction, fact, or retrieved context is indexed by Agent ID and Session ID.</p> <p>Crucially, it introduces Region Governance as a first-class citizen. You can strictly enforce that an agent's memory never leaves a specific geographic region (e.g., <code>europe-west1</code>), which is critical for enterprise applications handling sensitive user data.</p>"},{"location":"#why-use-it","title":"\ud83d\udca1 Why Use It?","text":"<ul> <li>Data Sovereignty &amp; Compliance: Native support for region governance. If an agent is configured for <code>europe-west1</code>, the SDK physically prevents writes to <code>us-central1</code> storage buckets.</li> <li>Backend Agnostic: Switch from Google Cloud Storage to AlloyDB, Redis, or Firestore without changing your agent code.</li> <li>Session Isolation: Automatically segregates memories by session, making it perfect for conversational agents and RAG pipelines.</li> <li>Production Ready: Typed, tested, and security-scanned. No hardcoded secrets.</li> </ul>"},{"location":"#how-it-works","title":"\u2699\ufe0f How It Works","text":"<p>The library uses an Adapter Pattern to connect to various storage backends. When you initialize a <code>MemoryClient</code>, you specify the Agent, Session, and Region.</p> <pre><code>graph LR\n    A[AI Agent] --&gt;|Write/Recall| B(MemoryClient)\n    B --&gt;|Region Check| C{Region Allowed?}\n    C --&gt;|Yes| D[Storage Adapter]\n    C --&gt;|No| E[Error]\n    D --&gt;|Persist| F[(GCS / AlloyDB / Redis)]</code></pre> <ol> <li>Initialize: Create a client with specific region constraints.</li> <li>Interact: Use <code>.write()</code> to save state and <code>.recall()</code> to fetch context.</li> <li>Govern: The SDK handles the routing and compliance checks transparently.</li> </ol>"},{"location":"#installation","title":"\ud83d\udee0\ufe0f Installation","text":"<pre><code>pip install agent-memory-hub\n\n# For specific backends\npip install \"agent-memory-hub[alloydb]\"\npip install \"agent-memory-hub[redis]\"\n</code></pre>"},{"location":"#quick-start-examples","title":"\u26a1 Quick Start &amp; Examples","text":"<p>We provide ready-to-use examples for common scenarios:</p>"},{"location":"#1-openai-agent-integration","title":"1. OpenAI Agent Integration","text":"<p>Inject long-term memory into your OpenAI API calls to personalize responses.</p> <ul> <li>View Example</li> </ul> <pre><code>from agent_memory_hub import MemoryClient\n# ... initialization ...\nmemory.write(\"User prefers concise Python code.\")\ncontext = memory.recall()\n# Inject 'context' into your system prompt\n</code></pre>"},{"location":"#2-multi-region-architecture","title":"2. Multi-Region Architecture","text":"<p>Manage distinct compliance requirements for global user bases.</p> <ul> <li>View Example</li> </ul> <pre><code># This client will ONLY write to EU-based storage\neu_memory = MemoryClient(agent_id=\"eu_bot\", region=\"europe-west1\", region_restricted=True)\n</code></pre>"},{"location":"#3-rag-agent-with-memory","title":"3. RAG Agent with Memory","text":"<p>Enhance Retrieval-Augmented Generation (RAG) by caching retrieved context and user interactions.</p> <ul> <li>View Example</li> </ul>"},{"location":"#documentation","title":"\ud83d\udcda Documentation","text":"<ul> <li>Benchmarking Guide</li> <li>Security &amp; Access Flow</li> <li>Semantic Memory Models</li> </ul>"},{"location":"architecture/","title":"Agent Memory Hub Architecture","text":"<p>This document describes the high-level architecture and data flow of the <code>agent-memory-hub</code> package.</p>"},{"location":"architecture/#high-level-architecture","title":"High-Level Architecture","text":"<p>The <code>agent-memory-hub</code> is designed with a layered architecture to ensure separation of concerns between public API, governance (region enforcement), and data persistence.</p> <pre><code>graph TD\n    Agent[\"Agent (LLM)\"] --&gt; Client[\"MemoryClient\"]\n\n    subgraph \"Agent Memory Hub\"\n        Client --&gt; Router[\"MemoryRouter\"]\n\n        Router --&gt; Guard[\"RegionGuard\"]\n        Router --&gt; Factory[\"StoreFactory\"]\n\n        Factory --&gt; Store[\"SessionStore (Interface)\"]\n    end\n\n    subgraph \"Data Plane\"\n        Store -.-&gt;|Implements| ADK[\"AdkSessionStore\"]\n        ADK --&gt; GCS[(\"Google Cloud Storage\")]\n    end\n\n    classDef component fill:#e1f5fe,stroke:#01579b,stroke-width:2px;\n    classDef storage fill:#fff3e0,stroke:#ff6f00,stroke-width:2px;\n\n    class Client,Router,Guard,Factory,Store component;\n    class ADK,GCS storage;</code></pre>"},{"location":"architecture/#component-overview","title":"Component Overview","text":""},{"location":"architecture/#1-client-layer-memoryclient","title":"1. Client Layer (<code>MemoryClient</code>)","text":"<p>The entry point for the application. It initializes the session context (Agent ID, Session ID) and configures the region requirements.</p> <ul> <li>Responsibility: Public API, Session Context management.</li> </ul>"},{"location":"architecture/#2-routing-layer-memoryrouter","title":"2. Routing Layer (<code>MemoryRouter</code>)","text":"<p>Acts as the central coordinator. It receives requests from the client and ensures they are routed to the correct data store while enforcing governance rules.</p> <ul> <li>Responsibility: Coordination, Enforcing interaction between Guard and Store.</li> </ul>"},{"location":"architecture/#3-control-plane-regionguard","title":"3. Control Plane (<code>RegionGuard</code>)","text":"<p>The governance engine. It validates that operations are permitted in the requested region.</p> <ul> <li>Responsibility: Data Sovereignty enforcement, Region validation.</li> </ul>"},{"location":"architecture/#4-data-plane-storefactory-sessionstore","title":"4. Data Plane (<code>StoreFactory</code> &amp; <code>SessionStore</code>)","text":"<p>Manages the physical persistence of data.</p> <ul> <li>StoreFactory: Abstraction to create the correct store backend based on configuration (e.g., ADK/GCS).</li> <li>SessionStore: Abstract interface for CRUD operations.</li> <li>AdkSessionStore: Concrete implementation using Google Cloud Storage.</li> </ul>"},{"location":"architecture/#data-flow","title":"Data Flow","text":""},{"location":"architecture/#write-operation-flow","title":"Write Operation Flow","text":"<p>This sequence diagram illustrates how a memory write operation is governed and verified before reaching storage.</p> <pre><code>sequenceDiagram\n    participant Agent\n    participant Client as MemoryClient\n    participant Router as MemoryRouter\n    participant Guard as RegionGuard\n    participant Store as AdkSessionStore\n\n    Agent-&gt;&gt;Client: write(key, value)\n    Client-&gt;&gt;Router: write(session_id, key, value)\n\n    rect rgb(240, 248, 255)\n        note right of Router: Region Governance Check\n        Router-&gt;&gt;Guard: check_residency(current_region)\n        Guard--&gt;&gt;Router: OK (or Raise Error)\n    end\n\n    Router-&gt;&gt;Store: write(session_id, key, value)\n    Store-&gt;&gt;Store: _get_bucket()\n    Store-&gt;&gt;GoogleCloud: upload_blob()\n    GoogleCloud--&gt;&gt;Store: Success\n    Store--&gt;&gt;Router: Success\n    Router--&gt;&gt;Client: Success\n    Client--&gt;&gt;Agent: Success</code></pre>"},{"location":"architecture/#read-operation-flow","title":"Read Operation Flow","text":"<p>Reading follows a similar governed path to ensure data is retrieved from the expected region.</p> <pre><code>sequenceDiagram\n    participant Agent\n    participant Client as MemoryClient\n    participant Router as MemoryRouter\n    participant Store as AdkSessionStore\n\n    Agent-&gt;&gt;Client: recall(key)\n    Client-&gt;&gt;Router: read(session_id, key)\n\n    Router-&gt;&gt;Router: RegionGuard.check_residency()\n\n    Router-&gt;&gt;Store: read(session_id, key)\n    Store-&gt;&gt;GoogleCloud: download_blob()\n    GoogleCloud--&gt;&gt;Store: JSON Data\n    Store--&gt;&gt;Router: Value\n    Router--&gt;&gt;Client: Value\n    Client--&gt;&gt;Agent: Value</code></pre>"},{"location":"architecture/#security-governance-model","title":"Security &amp; Governance Model","text":"<ol> <li>Strict Region Check: The <code>RegionGuard</code> is initialized with a specific region. Any operation routed through the <code>MemoryRouter</code> triggers a check against this guard. If the context of the operation does not match the locked region, a <code>RuntimeError</code> is raised immediately, preventing cross-region data leaks.</li> <li>No Credentials in Code: The <code>AdkSessionStore</code> uses <code>google.auth.default()</code>, ensuring that no secrets are handled by the library itself. Identity is managed via IAM roles attached to the compute environment.</li> </ol>"},{"location":"architecture/#agent-integration-pattern","title":"Agent Integration Pattern","text":"<p>This section visualizes how an Autonomous Agent (e.g., a ReAct loop) integrates with the Memory Hub. The Agent uses the Hub as its long-term memory store between reasoning steps.</p> <pre><code>sequenceDiagram\n    participant LLM as LLM Model\n    participant Agent as Agent Loop\n    participant Tools as Tool Executor\n    participant Memory as MemoryClient\n\n    Note over Agent: New Task Received\n\n    Agent-&gt;&gt;Memory: recall(\"task_history\")\n    Memory--&gt;&gt;Agent: Previous context/learnings\n\n    Agent-&gt;&gt;LLM: Prompt (Context + New Task)\n    LLM--&gt;&gt;Agent: \"Thought: I need to use Tool A...\"\n\n    Agent-&gt;&gt;Tools: Execute Tool A\n    Tools--&gt;&gt;Agent: Tool Output\n\n    Agent-&gt;&gt;Memory: write(\"intermediate_step\", Tool Output)\n    Memory--&gt;&gt;Agent: Acknowledged\n\n    Agent-&gt;&gt;LLM: Prompt (Update with Tool Output)\n    LLM--&gt;&gt;Agent: \"Final Answer: ...\"\n\n    Agent-&gt;&gt;Memory: write(\"final_result\", Answer)</code></pre> <p>The <code>MemoryClient</code> serves as the state persistence layer for the Agent, allowing it to remain stateless itself while maintaining continuity across complex, multi-step execution flows.</p>"},{"location":"benchmarking/","title":"Agent Memory Hub Benchmarking Guide","text":"<p>This guide describes how to use the <code>benchmark_db.py</code> script to evaluate the performance (latency and payload handling) of different memory backends supported by Agent Memory Hub.</p>"},{"location":"benchmarking/#overview","title":"Overview","text":"<p>The benchmarking script (<code>benchmark_db.py</code>) performs a series of Write and Read operations with varying payload sizes (1KB, 10KB, 100KB, 500KB) to measure:</p> <ol> <li>Write Latency: Time taken to persist data.</li> <li>Read Latency: Time taken to retrieve data.</li> <li>Data Integrity: Verifies that retrieved data matches the stored payload.</li> </ol>"},{"location":"benchmarking/#prerequisites","title":"Prerequisites","text":"<p>Before running the benchmark, ensure you have:</p> <ol> <li>Installed Dependencies: The package and its dependencies must be installed.     <pre><code>pip install .\n</code></pre></li> <li>Cloud Credentials:<ul> <li>For GCS (ADK): Ensure you have active Google Cloud credentials (e.g., via <code>gcloud auth application-default login</code>).</li> <li>For AlloyDB: You need the AlloyDB instance connection name, database user, password, and database name. Also ensure you have the <code>alloydb</code> extras installed: <pre><code>pip install \".[alloydb]\"\n</code></pre></li> </ul> </li> </ol>"},{"location":"benchmarking/#running-the-benchmark","title":"Running the Benchmark","text":""},{"location":"benchmarking/#1-google-cloud-storage-adk-backend","title":"1. Google Cloud Storage (ADK) Backend","text":"<p>To benchmark the default Google Cloud Storage backend:</p> <pre><code>python benchmark_db.py --backend adk --region us-central1 --env dev\n</code></pre> <p>Parameters:</p> <ul> <li><code>--backend</code>: Set to <code>adk</code> (default).</li> <li><code>--region</code>: GCP Region (default: <code>us-central1</code>).</li> <li><code>--env</code>: Environment tag used in bucket naming (default: <code>dev</code>).</li> </ul>"},{"location":"benchmarking/#2-alloydb-backend","title":"2. AlloyDB Backend","text":"<p>To benchmark the AlloyDB backend, you must provide connection details:</p> <pre><code>python benchmark_db.py \\\n  --backend alloydb \\\n  --region us-central1 \\\n  --env dev \\\n  --db-user &lt;YOUR_DB_USER&gt; \\\n  --db-pass &lt;YOUR_DB_PASSWORD&gt; \\\n  --db-name &lt;YOUR_DB_NAME&gt; \\\n  --db-conn &lt;PROJECT:REGION:INSTANCE&gt;\n</code></pre> <p>Parameters:</p> <ul> <li><code>--backend</code>: Set to <code>alloydb</code>.</li> <li><code>--db-user</code>: Your database username.</li> <li><code>--db-pass</code>: Your database password.</li> <li><code>--db-name</code>: The name of the database to use.</li> <li><code>--db-conn</code>: The AlloyDB Instance Connection Name (e.g., <code>my-project:us-central1:my-instance</code>).</li> <li>Note: This requires the <code>alloydb</code> extra: <code>pip install \".[alloydb]\"</code></li> </ul>"},{"location":"benchmarking/#3-redis-memorystore-backend","title":"3. Redis (Memorystore) Backend","text":"<p>To benchmark Redis:</p> <pre><code>python benchmark_db.py --backend redis --region us-central1 --redis-host &lt;HOST&gt; --redis-port &lt;PORT&gt;\n</code></pre> <p>Parameters:</p> <ul> <li><code>--backend</code>: Set to <code>redis</code>.</li> <li><code>--redis-host</code>: Hostname or IP of the Redis instance.</li> <li><code>--redis-port</code>: Port (default: 6379).</li> <li>Note: This requires the <code>redis</code> extra: <code>pip install \".[redis]\"</code></li> </ul>"},{"location":"benchmarking/#4-firestore-backend","title":"4. Firestore Backend","text":"<p>To benchmark Firestore:</p> <pre><code># Ensure GOOGLE_APPLICATION_CREDENTIALS is set\npython benchmark_db.py --backend firestore --region us-central1\n</code></pre> <p>Parameters:</p> <ul> <li><code>--backend</code>: Set to <code>firestore</code>.</li> <li>Note: This requires the <code>firestore</code> extra: <code>pip install \".[firestore]\"</code></li> <li>Note: Firestore credentials are usually inferred from the environment.</li> </ul>"},{"location":"benchmarking/#interpreting-results","title":"Interpreting Results","text":"<p>The script outputs a table similar to this:</p> <pre><code>==================================================\nBENCHMARK RESULTS: ADK\n==================================================\nSize (KB)  | Write (s)  | Read (s)   | Status\n--------------------------------------------------\n1          | 0.0452     | 0.0321     | SUCCESS\n10         | 0.0510     | 0.0385     | SUCCESS\n100        | 0.1250     | 0.0910     | SUCCESS\n500        | 0.4502     | 0.3801     | SUCCESS\n==================================================\n</code></pre> <ul> <li>Low Latency: Smaller numbers are better.</li> <li>Scalability: Observe how latency increases as payload size increases.</li> <li>Status: Should always be <code>SUCCESS</code>. <code>DATA MISMATCH</code> indicates data corruption, and <code>ERROR</code>/<code>FAIL</code> indicates connection or storage issues.</li> </ul>"},{"location":"contributing/","title":"Contributing to Agent Memory Hub","text":"<p>We welcome contributions! Please follow these guidelines to ensure a smooth process.</p>"},{"location":"contributing/#development-setup","title":"Development Setup","text":"<ol> <li>Clone the repository.</li> <li>Install dependencies:    <pre><code>pip install -e .[dev]\n</code></pre></li> <li>Run tests:    <pre><code>pytest\n</code></pre></li> </ol>"},{"location":"contributing/#pull-request-process","title":"Pull Request Process","text":"<ol> <li>Create a new branch for your feature or fix.</li> <li>Ensure all tests pass.</li> <li>Add new tests for any new functionality.</li> <li>Ensure 80% minimum code coverage.</li> <li>Update documentation if necessary.</li> <li>Submit a PR with a clear description of changes.</li> </ol>"},{"location":"contributing/#coding-standards","title":"Coding Standards","text":"<ul> <li>Use strict type hints.</li> <li>Write docstrings for all public methods.</li> <li>Run <code>ruff check .</code> before submitting.</li> <li>Avoid hardcoding any credentials.</li> </ul>"},{"location":"publishing/","title":"Publishing Guide","text":"<p>This guide explains how to publish the <code>agent-memory-hub</code> package to PyPI.</p>"},{"location":"publishing/#prerequisites","title":"Prerequisites","text":"<ol> <li>PyPI Account: You must have an account on PyPI.</li> <li>GitHub Secrets: You need to configure a secret in your GitHub repository to allow the CI workflow to authenticate with PyPI.</li> </ol>"},{"location":"publishing/#step-1-generate-an-api-token","title":"Step 1: Generate an API Token","text":"<ol> <li>Log in to your PyPI account.</li> <li>Go to Account Settings -&gt; API Tokens.</li> <li>Click Add API Token.</li> <li>Token Name: <code>agent-memory-hub-github-action</code> (or similar).</li> <li>Scope: Select \"Entire account (all projects)\" for the first publish (since the project doesn't exist yet). After the first publish, you can scope it to just this project.</li> <li>Click Add Token.</li> <li>Copy the token immediately. It will start with <code>pypi-</code>.</li> </ol>"},{"location":"publishing/#step-2-configure-github-secrets","title":"Step 2: Configure GitHub Secrets","text":"<ol> <li>Go to your GitHub repository.</li> <li>Click Settings -&gt; Secrets and variables -&gt; Actions.</li> <li>Click New repository secret.</li> <li>Name: <code>PYPI_API_TOKEN</code></li> <li>Secret: Paste the token you copied from PyPI.</li> <li>Click Add secret.</li> </ol>"},{"location":"publishing/#step-3-trigger-a-release","title":"Step 3: Trigger a Release","text":"<p>The publishing process is automated. To publish a new version:</p> <ol> <li>Update the <code>version</code> in <code>pyproject.toml</code> (e.g., to <code>0.1.1</code>).</li> <li>Commit and push changes.</li> <li>Go to the Releases section in your GitHub repository.</li> <li>Draft a new release.<ul> <li>Tag version: <code>v0.1.1</code></li> <li>Title: <code>Release v0.1.1</code></li> </ul> </li> <li>Click Publish release.</li> </ol> <p>The <code>.github/workflows/publish.yml</code> workflow will automatically run, build the package, and upload it to PyPI.</p>"},{"location":"security_access/","title":"Security &amp; Access Control Architecture","text":"<p>This document details the security model of Agent Memory Hub, specifically how Identity and Access Management (IAM), Service Accounts, and logical isolation work together to secure memory data.</p>"},{"location":"security_access/#identity-model","title":"Identity Model","text":"<p>Agent Memory Hub follows a Service Identity model. The \"User\" in this context is typically an AI Agent process running in a cloud environment (e.g., Cloud Run, GKE, VM).</p> <p>Access is granted to the Agent's Identity (Service Account), not to individual end-users of the agent application.</p>"},{"location":"security_access/#flow-diagram-authorization-path","title":"Flow Diagram: Authorization Path","text":"<pre><code>sequenceDiagram\n    participant Agent as AI Agent (Client)\n    participant SDK as Memory Client SDK\n    participant IAM as Cloud IAM / Auth\n    participant Resource as Storage (GCS/DB)\n\n    Note over Agent, SDK: Running with Service Account (SA) Identity\n\n    Agent-&gt;&gt;SDK: write(session_id=\"sess_123\", key=\"fact\")\n\n    SDK-&gt;&gt;IAM: Request Access Token (Implicit via ADC)\n    IAM--&gt;&gt;SDK: Access Token\n\n    SDK-&gt;&gt;Resource: API Call (Bearer Token)\n\n    Note over Resource: Verify SA has permission on specific Bucket/Table\n\n    alt Permission Granted\n        Resource--&gt;&gt;SDK: Success\n        SDK--&gt;&gt;Agent: Success\n    else Permission Denied\n        Resource--&gt;&gt;SDK: 403 Forbidden\n        SDK--&gt;&gt;Agent: Error (Access Denied)\n    end</code></pre>"},{"location":"security_access/#iam-permissions","title":"IAM &amp; Permissions","text":"<p>Security is enforced at the Infrastructure Layer. The Service Account running the agent need minimal privileges.</p>"},{"location":"security_access/#recommended-roles-google-cloud","title":"Recommended Roles (Google Cloud)","text":"Backend Recommended Role Granularity Capability GCS (ADK) <code>roles/storage.objectCreator</code><code>roles/storage.objectViewer</code> Bucket Level Can only read/write objects in the specific regional bucket. Cannot list other buckets. Firestore <code>roles/datastore.user</code> Project/Database Read/write access to documents. Use Firestore Rules for finer grain. AlloyDB <code>roles/alloydb.client</code> Instance Ability to connect. Internal DB roles restrict data access."},{"location":"security_access/#isolation-strategies","title":"Isolation Strategies","text":"<p>How do we recall sure Agent A doesn't read Agent B's memory?</p>"},{"location":"security_access/#1-logical-isolation-standard","title":"1. Logical Isolation (Standard)","text":"<ul> <li>Mechanism: The SDK silos data using <code>session_id</code> and <code>agent_id</code> prefixes in object keys or tables.</li> <li>Setup: Shared Service Account, Shared Bucket.</li> <li>Trust: The Agents are trusted code components.</li> <li>Risk: If Agent A is compromised and modifies the SDK code, it could read Agent B's data because the Identity (SA) has access to the whole bucket.</li> </ul>"},{"location":"security_access/#2-infrastructure-isolation-strictmulti-tenant","title":"2. Infrastructure Isolation (Strict/Multi-Tenant)","text":"<ul> <li>Mechanism: Separate physical resources (Buckets) and Identities (Service Accounts) for different agent groups.</li> <li>Setup:</li> <li>Agent A runs as <code>SA-A</code> -&gt; Has access ONLY to <code>bucket-region-a</code>.</li> <li>Agent B runs as <code>SA-B</code> -&gt; Has access ONLY to <code>bucket-region-b</code>.</li> <li>Benefit: Even if Agent A is fully compromised, the infrastructure layer denies access to Agent B's bucket.</li> </ul>"},{"location":"security_access/#diagram-strict-isolation-flow","title":"Diagram: Strict Isolation Flow","text":"<pre><code>flowchart TD\n    subgraph Trusted Zone A\n        AgentA[Agent Process A]\n        CredsA[Service Account A]\n        AgentA --- CredsA\n    end\n\n    subgraph Trusted Zone B\n        AgentB[Agent Process B]\n        CredsB[Service Account B]\n        AgentB --- CredsB\n    end\n\n    subgraph Cloud Infrastructure\n        IAM[Cloud IAM Policy]\n\n        BucketA[(Bucket: Memory A)]\n        BucketB[(Bucket: Memory B)]\n\n        CredsA --&gt;|Allowed| BucketA\n        CredsA -.-&gt;|DENIED| BucketB\n\n        CredsB --&gt;|Allowed| BucketB\n        CredsB -.-&gt;|DENIED| BucketA\n    end</code></pre>"},{"location":"security_access/#configuring-service-accounts","title":"Configuring Service Accounts","text":"<p>To setup a Service Account (SA) for an agent:</p> <ol> <li>Create SA:     <pre><code>gcloud iam service-accounts create agent-memory-reader\n</code></pre></li> <li>Grant Permissions (Least Privilege):     <pre><code># Only grant access to the specific memory bucket\ngsutil iam ch serviceAccount:agent-memory-reader@PROJECT.iam.gserviceaccount.com:objectCreator gs://memory-hub-us-central1-prod\n</code></pre></li> <li>Run Agent:<ul> <li>Local: <code>export GOOGLE_APPLICATION_CREDENTIALS=\"path/to/key.json\"</code></li> <li>Cloud Run/GCE: Attach the Service Account to the instance. The SDK detects it automatically.</li> </ul> </li> </ol>"},{"location":"security_access/#rbac-for-databases-alloydbredis","title":"RBAC for Databases (AlloyDB/Redis)","text":"<p>For Database backends, security is two-fold:</p> <ol> <li>Cloud Access: IAM controls \"Who can connect to the instance\".</li> <li>Database Access: Internal users/roles control \"Who can read table X\".</li> </ol> <p>The SDK supports passing <code>user</code> and <code>password</code> via configuration to leverage these internal database entry controls.</p>"},{"location":"semantic_models/","title":"Semantic Memory Models","text":"<p>Agent Memory Hub v0.4.0 introduces typed, semantic memory models. This allows you to work with structured concepts like \"Events\", \"Facts\", and \"Profiles\" rather than raw JSON blobs.</p>"},{"location":"semantic_models/#philosophy","title":"Philosophy","text":"<p>By enforcing schema on memory, we enable:</p> <ol> <li>Reliable Extraction: Ensure memories generated by LLMs conform to a known structure.</li> <li>Smarter Retrieval: Filter by type (e.g., \"Give me all facts about Python\").</li> <li>Knowledge Graphs: Link memories together using IDs and source references.</li> </ol>"},{"location":"semantic_models/#available-models","title":"Available Models","text":""},{"location":"semantic_models/#1-episodicmemory","title":"1. EpisodicMemory","text":"<p>Records an event, conversation turn, or tool execution.</p> <ul> <li><code>content</code>: The textual description of what happened.</li> <li><code>source</code>: E.g., \"conversation\", \"calendar\", \"tool_trace\".</li> <li><code>participants</code>: List of actor IDs involved.</li> </ul>"},{"location":"semantic_models/#2-semanticmemory","title":"2. SemanticMemory","text":"<p>Represents a distinctive fact or piece of knowledge (Subject-Predicate-Object).</p> <ul> <li><code>subject</code>: \"User\"</li> <li><code>predicate</code>: \"prefers\"</li> <li><code>object</code>: \"Dark Mode\"</li> <li><code>truth_score</code>: 0.0 to 1.0 confidence.</li> </ul>"},{"location":"semantic_models/#3-entitymemory","title":"3. EntityMemory","text":"<p>A profile for a stable entity.</p> <ul> <li><code>entity_id</code>: Unique reference (e.g., \"user_123\").</li> <li><code>attributes</code>: Dictionary of traits (age, name, role).</li> </ul>"},{"location":"semantic_models/#usage-example","title":"Usage Example","text":"<pre><code>from agent_memory_hub import MemoryClient\nfrom agent_memory_hub.models import EpisodicMemory, SemanticMemory, MemoryScope\n\nclient = MemoryClient(agent_id=\"researcher\", session_id=\"sess_1\")\n\n# 1. Store a Fact\nfact = SemanticMemory(\n    agent_id=\"researcher\",\n    subject=\"Python\",\n    predicate=\"released_year\",\n    object=\"1991\",\n    scope=MemoryScope.GLOBAL,\n    tags=[\"programming\", \"history\"]\n)\nclient.write_model(fact)\n\n# 2. Store an Episode\nepisode = EpisodicMemory(\n    agent_id=\"researcher\",\n    content=\"User asked about Python history.\",\n    participants=[\"user_1\", \"researcher\"]\n)\nclient.write_model(episode)\n</code></pre>"},{"location":"guides/multi_region/","title":"Multi-Region Memory Architecture","text":"<p><code>agent-memory-hub</code> excels in scenarios where data sovereignty is paramount. This guide explains how to set up strict region governance.</p>"},{"location":"guides/multi_region/#the-concept","title":"The Concept","text":"<p>In a global application, you might have users in Europe (GDPR) and the US. You want to ensure:</p> <ul> <li>European user data never leaves the EU region (<code>europe-west1</code>).</li> <li>US user data stays in the US (<code>us-central1</code>).</li> </ul>"},{"location":"guides/multi_region/#configuration","title":"Configuration","text":"<p>You can enforce this at the client level using the <code>region_restricted=True</code> flag.</p>"},{"location":"guides/multi_region/#european-agent","title":"European Agent","text":"<pre><code>eu_memory = MemoryClient(\n    agent_id=\"eu_support_bot\",\n    region=\"europe-west1\",\n    region_restricted=True\n)\n</code></pre> <p>If this client attempts to write to a bucket that is NOT in <code>europe-west1</code>, the operation will fail with a <code>RegionViolationError</code>.</p>"},{"location":"guides/multi_region/#us-agent","title":"US Agent","text":"<pre><code>us_memory = MemoryClient(\n    agent_id=\"us_support_bot\",\n    region=\"us-central1\",\n    region_restricted=True\n)\n</code></pre>"},{"location":"guides/multi_region/#storage-backend-setup","title":"Storage Backend Setup","text":"<p>Ensure your underlying storage is correctly provisioned:</p> <ul> <li>Google Cloud Storage: Create buckets named <code>memory-hub-europe-west1-prod</code> and <code>memory-hub-us-central1-prod</code>.</li> <li>AlloyDB: Provision instances in the respective regions.</li> </ul> <p>The <code>MemoryClient</code> expects the backend resource to verify its own location. For GCS, we check the bucket's location metadata.</p>"},{"location":"guides/openai_integration/","title":"OpenAI Agents Integration","text":"<p>This guide demonstrates how to integrate <code>agent-memory-hub</code> with direct OpenAI API calls to create stateful agents.</p>"},{"location":"guides/openai_integration/#overview","title":"Overview","text":"<p>Stateless models like GPT-4 do not remember previous interactions. By using <code>agent-memory-hub</code>, you can fetch relevant context from previous sessions and inject it into the <code>system</code> prompt of your current generation.</p>"},{"location":"guides/openai_integration/#implementation","title":"Implementation","text":"<p>The core pattern involves:</p> <ol> <li>Recall: Fetch relevant memories before calling the LLM.</li> <li>Augment: Add these memories to the conversation history or system prompt.</li> <li>Generate: Call the OpenAI API.</li> <li>Store: Save the new interaction (user query + agent response) back to memory.</li> </ol>"},{"location":"guides/openai_integration/#code-example","title":"Code Example","text":"<p>Below is a simplified snippets from our <code>examples/openai_agents_integration.py</code> script.</p> <pre><code>import openai\nfrom agent_memory_hub import MemoryClient\n\n# 1. Initialize Memory\nmemory = MemoryClient(agent_id=\"my_agent\", session_id=\"session_1\")\n\n# 2. Recall Context\nrecent_memories = memory.recall(limit=5)\ncontext_str = \"\\n\".join([m['content'] for m in recent_memories])\n\n# 3. Augment System Prompt\nsystem_prompt = f\"\"\"\nYou are a helpful assistant.\nHere is what you know about the user:\n{context_str}\n\"\"\"\n\n# 4. Call OpenAI\nresponse = openai.chat.completions.create(\n    model=\"gpt-4\",\n    messages=[\n        {\"role\": \"system\", \"content\": system_prompt},\n        {\"role\": \"user\", \"content\": \"Book me a flight to my usual destination.\"}\n    ]\n)\n</code></pre>"},{"location":"guides/openai_integration/#best-practices","title":"Best Practices","text":"<ul> <li>Summarization: If memory grows too large, consider having a background process summarize older memories into concise facts.</li> <li>Metadata: Store metadata like <code>topic</code> or <code>sentiment</code> to filter memories later during recall.</li> </ul>"},{"location":"guides/rag_memory/","title":"RAG Agent with Stateful Memory","text":"<p>Retrieval-Augmented Generation (RAG) combines search with generation. <code>agent-memory-hub</code> adds a third pillar: State.</p>"},{"location":"guides/rag_memory/#why-state-in-rag","title":"Why State in RAG?","text":"<p>Standard RAG retrieves documents based on the query. However, it often forgets:</p> <ol> <li>What was retrieved previously: Avoiding redundant searches.</li> <li>User preferences: If a user said \"I prefer technical docs\" 3 turns ago, the RAG retrieval should bias towards that.</li> <li>Conversation history: Multi-turn context.</li> </ol>"},{"location":"guides/rag_memory/#integration-flow","title":"Integration Flow","text":"<ol> <li>User Query: \"How do I configure Redis?\"</li> <li>Memory Check: Agent checks <code>memory.recall()</code> for \"Redis configuration\" in recent conversational items.</li> <li>Retrieval: If not sufficiently answered in memory, search the vector DB / knowledge base.</li> <li>Synthesis: Generate answer.</li> <li>Write Back: Store the Result and the Source/Context in <code>agent-memory-hub</code>.</li> </ol> <pre><code># Pseudo-code flow\nquery = \"How do I configure Redis?\"\n\n# Check Memory\nmemories = memory.recall(query=query) # Semantic search over memory\nif not memories:\n    docs = vector_db.search(query)\n    memory.write(f\"Retrieved docs for {query}: {docs[0].summary}\")\n    answer = llm.generate(query, context=docs)\nelse:\n    answer = llm.generate(query, context=memories)\n\nmemory.write(f\"User asked {query}, Answered: {answer}\")\n</code></pre> <p>See <code>examples/rag_agent_with_region_memory.py</code> for a runnable example.</p>"},{"location":"reference/client/","title":"Memory Client","text":""},{"location":"reference/client/#agent_memory_hub.client.memory_client.MemoryClient","title":"<code>agent_memory_hub.client.memory_client.MemoryClient</code>","text":"<p>Client for accessing agent memory with region governance.</p> Source code in <code>agent_memory_hub/client/memory_client.py</code> <pre><code>class MemoryClient:\n    \"\"\"\n    Client for accessing agent memory with region governance.\n    \"\"\"\n\n    def __init__(\n        self,\n        agent_id: str,\n        session_id: str,\n        region: str = DEFAULT_REGION,\n        region_restricted: bool = True,\n        backend: str = \"adk\",\n        ttl_seconds: Optional[int] = None,\n        alloydb_config: Optional[\"AlloyDBConfig\"] = None,\n        redis_config: Optional[\"RedisConfig\"] = None,\n        environment: str = \"prod\",\n    ):\n        \"\"\"\n        Initialize the MemoryClient.\n\n        Args:\n            agent_id: Unique identifier for the agent.\n            session_id: Unique identifier for the session.\n            region: The cloud region where memory should be stored/retrieved.\n            region_restricted: If True, enforces strict region checks.\n            backend: Storage backend (\"adk\" for GCS, \"alloydb\" for AlloyDB).\n            ttl_seconds: Time-to-live in seconds (None = no expiry).\n            alloydb_config: AlloyDB configuration (required if backend=\"alloydb\").\n            redis_config: Redis configuration (optional if backend=\"redis\").\n            environment: Environment context (e.g., \"prod\", \"dev\") for resource naming.\n        \"\"\"\n        if not agent_id:\n            raise ValueError(\"agent_id cannot be empty\")\n        if not session_id:\n            raise ValueError(\"session_id cannot be empty\")\n        self.agent_id = agent_id\n        self.session_id = session_id\n        self.region = region\n        self.region_restricted = region_restricted\n        self.backend = backend\n        self.ttl_seconds = ttl_seconds\n        self.environment = environment\n        self._tracer = get_tracer()\n\n        if region_restricted:\n            self._guard = RegionGuard(region)\n            self._router = MemoryRouter(\n                region_guard=self._guard,\n                backend=backend,\n                ttl_seconds=ttl_seconds,\n                alloydb_config=alloydb_config,\n                redis_config=redis_config,\n                environment=environment,\n            )\n        else:\n            # Fallback or less strict mode not fully implemented in spec, \n            # assuming guard is always used but maybe with relaxed checks if requested.\n            # For now, we strictly follow the requested design where region is passed.\n            self._guard = RegionGuard(region)\n            self._router = MemoryRouter(\n                region_guard=self._guard,\n                backend=backend,\n                ttl_seconds=ttl_seconds,\n                alloydb_config=alloydb_config,\n                redis_config=redis_config,\n                environment=environment,\n            )\n\n    def write(self, value: Any, key: str = \"default\") -&gt; None:\n        \"\"\"\n        Write a value to the memory store.\n\n        Args:\n            value: The data to store.\n            key: specific key or context for the memory (e.g., 'episodic', 'semantic').\n        \"\"\"\n        with self._tracer.start_as_current_span(\"MemoryClient.write\") as span:\n            span.set_attribute(\"agent.id\", self.agent_id)\n            span.set_attribute(\"session.id\", self.session_id)\n            span.set_attribute(\"region\", self.region)\n            span.set_attribute(\"memory.key\", key)\n\n            # Composite key could include agent_id to namespace it\n            composite_key = f\"{self.agent_id}/{key}\"\n            self._router.write(self.session_id, composite_key, value)\n\n    def write_model(self, memory_model: \"BaseMemory\") -&gt; None:\n        \"\"\"\n        Write a semantic memory model to the store.\n\n        Args:\n            memory_model: Pydantic model instance (EpisodicMemory, SemanticMemory, etc.)\n        \"\"\"\n        # Ensure agent_id matches client if not set (though model has default)\n        if hasattr(memory_model, \"agent_id\") and not memory_model.agent_id:\n             memory_model.agent_id = self.agent_id\n\n        # Use model ID or content hash as key? \n        # For now, we use a predictable key scheme: type/id\n        key = f\"{memory_model.__class__.__name__.lower()}/{memory_model.id}\"\n\n        # Serialize to dict\n        value = memory_model.to_dict()\n\n        with self._tracer.start_as_current_span(\"MemoryClient.write_model\") as span:\n            span.set_attribute(\"memory.type\", memory_model.__class__.__name__)\n            span.set_attribute(\"memory.id\", memory_model.id)\n\n            self.write(value, key=key)\n\n    def recall(self, key: str = \"default\") -&gt; Optional[Any]:\n        \"\"\"\n        Recall a value from the memory store.\n\n        Args:\n            key: The key used during write.\n\n        Returns:\n            The stored value or None if not found.\n        \"\"\"\n        with self._tracer.start_as_current_span(\"MemoryClient.recall\") as span:\n            span.set_attribute(\"agent.id\", self.agent_id)\n            span.set_attribute(\"session.id\", self.session_id)\n            span.set_attribute(\"region\", self.region)\n            span.set_attribute(\"memory.key\", key)\n\n            composite_key = f\"{self.agent_id}/{key}\"\n            return self._router.read(self.session_id, composite_key)\n</code></pre>"},{"location":"reference/client/#agent_memory_hub.client.memory_client.MemoryClient.__init__","title":"<code>__init__(agent_id, session_id, region=DEFAULT_REGION, region_restricted=True, backend='adk', ttl_seconds=None, alloydb_config=None, redis_config=None, environment='prod')</code>","text":"<p>Initialize the MemoryClient.</p> <p>Parameters:</p> Name Type Description Default <code>agent_id</code> <code>str</code> <p>Unique identifier for the agent.</p> required <code>session_id</code> <code>str</code> <p>Unique identifier for the session.</p> required <code>region</code> <code>str</code> <p>The cloud region where memory should be stored/retrieved.</p> <code>DEFAULT_REGION</code> <code>region_restricted</code> <code>bool</code> <p>If True, enforces strict region checks.</p> <code>True</code> <code>backend</code> <code>str</code> <p>Storage backend (\"adk\" for GCS, \"alloydb\" for AlloyDB).</p> <code>'adk'</code> <code>ttl_seconds</code> <code>Optional[int]</code> <p>Time-to-live in seconds (None = no expiry).</p> <code>None</code> <code>alloydb_config</code> <code>Optional[AlloyDBConfig]</code> <p>AlloyDB configuration (required if backend=\"alloydb\").</p> <code>None</code> <code>redis_config</code> <code>Optional[RedisConfig]</code> <p>Redis configuration (optional if backend=\"redis\").</p> <code>None</code> <code>environment</code> <code>str</code> <p>Environment context (e.g., \"prod\", \"dev\") for resource naming.</p> <code>'prod'</code> Source code in <code>agent_memory_hub/client/memory_client.py</code> <pre><code>def __init__(\n    self,\n    agent_id: str,\n    session_id: str,\n    region: str = DEFAULT_REGION,\n    region_restricted: bool = True,\n    backend: str = \"adk\",\n    ttl_seconds: Optional[int] = None,\n    alloydb_config: Optional[\"AlloyDBConfig\"] = None,\n    redis_config: Optional[\"RedisConfig\"] = None,\n    environment: str = \"prod\",\n):\n    \"\"\"\n    Initialize the MemoryClient.\n\n    Args:\n        agent_id: Unique identifier for the agent.\n        session_id: Unique identifier for the session.\n        region: The cloud region where memory should be stored/retrieved.\n        region_restricted: If True, enforces strict region checks.\n        backend: Storage backend (\"adk\" for GCS, \"alloydb\" for AlloyDB).\n        ttl_seconds: Time-to-live in seconds (None = no expiry).\n        alloydb_config: AlloyDB configuration (required if backend=\"alloydb\").\n        redis_config: Redis configuration (optional if backend=\"redis\").\n        environment: Environment context (e.g., \"prod\", \"dev\") for resource naming.\n    \"\"\"\n    if not agent_id:\n        raise ValueError(\"agent_id cannot be empty\")\n    if not session_id:\n        raise ValueError(\"session_id cannot be empty\")\n    self.agent_id = agent_id\n    self.session_id = session_id\n    self.region = region\n    self.region_restricted = region_restricted\n    self.backend = backend\n    self.ttl_seconds = ttl_seconds\n    self.environment = environment\n    self._tracer = get_tracer()\n\n    if region_restricted:\n        self._guard = RegionGuard(region)\n        self._router = MemoryRouter(\n            region_guard=self._guard,\n            backend=backend,\n            ttl_seconds=ttl_seconds,\n            alloydb_config=alloydb_config,\n            redis_config=redis_config,\n            environment=environment,\n        )\n    else:\n        # Fallback or less strict mode not fully implemented in spec, \n        # assuming guard is always used but maybe with relaxed checks if requested.\n        # For now, we strictly follow the requested design where region is passed.\n        self._guard = RegionGuard(region)\n        self._router = MemoryRouter(\n            region_guard=self._guard,\n            backend=backend,\n            ttl_seconds=ttl_seconds,\n            alloydb_config=alloydb_config,\n            redis_config=redis_config,\n            environment=environment,\n        )\n</code></pre>"},{"location":"reference/client/#agent_memory_hub.client.memory_client.MemoryClient.recall","title":"<code>recall(key='default')</code>","text":"<p>Recall a value from the memory store.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key used during write.</p> <code>'default'</code> <p>Returns:</p> Type Description <code>Optional[Any]</code> <p>The stored value or None if not found.</p> Source code in <code>agent_memory_hub/client/memory_client.py</code> <pre><code>def recall(self, key: str = \"default\") -&gt; Optional[Any]:\n    \"\"\"\n    Recall a value from the memory store.\n\n    Args:\n        key: The key used during write.\n\n    Returns:\n        The stored value or None if not found.\n    \"\"\"\n    with self._tracer.start_as_current_span(\"MemoryClient.recall\") as span:\n        span.set_attribute(\"agent.id\", self.agent_id)\n        span.set_attribute(\"session.id\", self.session_id)\n        span.set_attribute(\"region\", self.region)\n        span.set_attribute(\"memory.key\", key)\n\n        composite_key = f\"{self.agent_id}/{key}\"\n        return self._router.read(self.session_id, composite_key)\n</code></pre>"},{"location":"reference/client/#agent_memory_hub.client.memory_client.MemoryClient.write","title":"<code>write(value, key='default')</code>","text":"<p>Write a value to the memory store.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Any</code> <p>The data to store.</p> required <code>key</code> <code>str</code> <p>specific key or context for the memory (e.g., 'episodic', 'semantic').</p> <code>'default'</code> Source code in <code>agent_memory_hub/client/memory_client.py</code> <pre><code>def write(self, value: Any, key: str = \"default\") -&gt; None:\n    \"\"\"\n    Write a value to the memory store.\n\n    Args:\n        value: The data to store.\n        key: specific key or context for the memory (e.g., 'episodic', 'semantic').\n    \"\"\"\n    with self._tracer.start_as_current_span(\"MemoryClient.write\") as span:\n        span.set_attribute(\"agent.id\", self.agent_id)\n        span.set_attribute(\"session.id\", self.session_id)\n        span.set_attribute(\"region\", self.region)\n        span.set_attribute(\"memory.key\", key)\n\n        # Composite key could include agent_id to namespace it\n        composite_key = f\"{self.agent_id}/{key}\"\n        self._router.write(self.session_id, composite_key, value)\n</code></pre>"},{"location":"reference/client/#agent_memory_hub.client.memory_client.MemoryClient.write_model","title":"<code>write_model(memory_model)</code>","text":"<p>Write a semantic memory model to the store.</p> <p>Parameters:</p> Name Type Description Default <code>memory_model</code> <code>BaseMemory</code> <p>Pydantic model instance (EpisodicMemory, SemanticMemory, etc.)</p> required Source code in <code>agent_memory_hub/client/memory_client.py</code> <pre><code>def write_model(self, memory_model: \"BaseMemory\") -&gt; None:\n    \"\"\"\n    Write a semantic memory model to the store.\n\n    Args:\n        memory_model: Pydantic model instance (EpisodicMemory, SemanticMemory, etc.)\n    \"\"\"\n    # Ensure agent_id matches client if not set (though model has default)\n    if hasattr(memory_model, \"agent_id\") and not memory_model.agent_id:\n         memory_model.agent_id = self.agent_id\n\n    # Use model ID or content hash as key? \n    # For now, we use a predictable key scheme: type/id\n    key = f\"{memory_model.__class__.__name__.lower()}/{memory_model.id}\"\n\n    # Serialize to dict\n    value = memory_model.to_dict()\n\n    with self._tracer.start_as_current_span(\"MemoryClient.write_model\") as span:\n        span.set_attribute(\"memory.type\", memory_model.__class__.__name__)\n        span.set_attribute(\"memory.id\", memory_model.id)\n\n        self.write(value, key=key)\n</code></pre>"},{"location":"reference/control_plane/","title":"Region Guard","text":""},{"location":"reference/control_plane/#agent_memory_hub.control_plane.region_guard.RegionGuard","title":"<code>agent_memory_hub.control_plane.region_guard.RegionGuard</code>","text":"<p>               Bases: <code>RegionAware</code></p> <p>Enforces region constraints for memory operations.</p> Source code in <code>agent_memory_hub/control_plane/region_guard.py</code> <pre><code>class RegionGuard(RegionAware):\n    \"\"\"\n    Enforces region constraints for memory operations.\n    \"\"\"\n    def __init__(self, region: str):\n        if region not in SUPPORTED_REGIONS:\n            raise ValueError(\n                f\"Region '{region}' is not supported. Supported: {SUPPORTED_REGIONS}\"\n            )\n        self._region = region\n\n    @property\n    def current_region(self) -&gt; str:\n        return self._region\n\n    def validate_region(self, target_region: str) -&gt; bool:\n        \"\"\"\n        Validates if the operation matches the guard's region.\n        \"\"\"\n        return self._region == target_region\n\n    def check_residency(self, operation_region: Optional[str] = None) -&gt; None:\n        \"\"\"\n        Raises generic RuntimeError if region mismatch.\n        \"\"\"\n        if operation_region and operation_region != self._region:\n             raise RuntimeError(\n                 f\"Region violation: Operation in '{operation_region}' \"\n                 f\"but guard locked to '{self._region}'\"\n             )\n</code></pre>"},{"location":"reference/control_plane/#agent_memory_hub.control_plane.region_guard.RegionGuard.check_residency","title":"<code>check_residency(operation_region=None)</code>","text":"<p>Raises generic RuntimeError if region mismatch.</p> Source code in <code>agent_memory_hub/control_plane/region_guard.py</code> <pre><code>def check_residency(self, operation_region: Optional[str] = None) -&gt; None:\n    \"\"\"\n    Raises generic RuntimeError if region mismatch.\n    \"\"\"\n    if operation_region and operation_region != self._region:\n         raise RuntimeError(\n             f\"Region violation: Operation in '{operation_region}' \"\n             f\"but guard locked to '{self._region}'\"\n         )\n</code></pre>"},{"location":"reference/control_plane/#agent_memory_hub.control_plane.region_guard.RegionGuard.validate_region","title":"<code>validate_region(target_region)</code>","text":"<p>Validates if the operation matches the guard's region.</p> Source code in <code>agent_memory_hub/control_plane/region_guard.py</code> <pre><code>def validate_region(self, target_region: str) -&gt; bool:\n    \"\"\"\n    Validates if the operation matches the guard's region.\n    \"\"\"\n    return self._region == target_region\n</code></pre>"},{"location":"reference/routing/","title":"Memory Router","text":""},{"location":"reference/routing/#agent_memory_hub.routing.memory_router.MemoryRouter","title":"<code>agent_memory_hub.routing.memory_router.MemoryRouter</code>","text":"<p>Routes read/write requests to the correct store, ensuring region compliance.</p> Source code in <code>agent_memory_hub/routing/memory_router.py</code> <pre><code>class MemoryRouter:\n    \"\"\"\n    Routes read/write requests to the correct store, ensuring region compliance.\n    \"\"\"\n    def __init__(\n        self, \n        region_guard: RegionGuard, \n        backend: str = \"adk\",\n        ttl_seconds: Optional[int] = None,\n        alloydb_config: Optional[\"AlloyDBConfig\"] = None,\n        redis_config: Optional[\"RedisConfig\"] = None,\n        environment: str = \"prod\",\n    ):\n        self.region_guard = region_guard\n        self.backend = backend\n        self.ttl_seconds = ttl_seconds\n        self.environment = environment\n        # Initialize store lazily or eagerly? Eagerly for router is fine.\n        self.store: SessionStore = StoreFactory.get_store(\n            backend=backend, \n            region=region_guard.current_region,\n            # Explicitly passing default to be safe, though not strictly needed\n            bucket_prefix=\"memory-hub\",\n            environment=environment,\n            ttl_seconds=ttl_seconds,\n            alloydb_config=alloydb_config,\n            redis_config=redis_config,\n        )\n\n    def write(self, session_id: str, key: str, value: Any) -&gt; None:\n        \"\"\"\n        Writes data ensuring regional compliance.\n        \"\"\"\n        # Double check residency (redundant but safe)\n        self.region_guard.check_residency(self.region_guard.current_region)\n        self.store.write(session_id, key, value)\n\n    def read(self, session_id: str, key: str) -&gt; Optional[Any]:\n        \"\"\"\n        Reads data.\n        \"\"\"\n        self.region_guard.check_residency(self.region_guard.current_region)\n        return self.store.read(session_id, key)\n</code></pre>"},{"location":"reference/routing/#agent_memory_hub.routing.memory_router.MemoryRouter.read","title":"<code>read(session_id, key)</code>","text":"<p>Reads data.</p> Source code in <code>agent_memory_hub/routing/memory_router.py</code> <pre><code>def read(self, session_id: str, key: str) -&gt; Optional[Any]:\n    \"\"\"\n    Reads data.\n    \"\"\"\n    self.region_guard.check_residency(self.region_guard.current_region)\n    return self.store.read(session_id, key)\n</code></pre>"},{"location":"reference/routing/#agent_memory_hub.routing.memory_router.MemoryRouter.write","title":"<code>write(session_id, key, value)</code>","text":"<p>Writes data ensuring regional compliance.</p> Source code in <code>agent_memory_hub/routing/memory_router.py</code> <pre><code>def write(self, session_id: str, key: str, value: Any) -&gt; None:\n    \"\"\"\n    Writes data ensuring regional compliance.\n    \"\"\"\n    # Double check residency (redundant but safe)\n    self.region_guard.check_residency(self.region_guard.current_region)\n    self.store.write(session_id, key, value)\n</code></pre>"}]}